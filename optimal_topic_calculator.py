#!/usr/bin/env python3
"""
LDA Optimal Topic Number Calculator

Bu script, verilen belge sayÄ±sÄ± iÃ§in optimal LDA konu sayÄ±sÄ±nÄ± hesaplar.
Birden fazla matematiksel yaklaÅŸÄ±m kullanÄ±r:

1. Rule of Thumb formÃ¼lleri (sqrt, log, fixed ratios)
2. Perplexity-based hesaplama
3. Coherence score optimizasyonu
4. Akademik literatÃ¼r Ã¶nerileri

103,576 makale iÃ§in optimal konu sayÄ±sÄ±nÄ± belirler.
"""

import math
import numpy as np
from collections import Counter

def calculate_optimal_topics(num_documents, avg_doc_length=None, vocabulary_size=None):
    """
    FarklÄ± yÃ¶ntemlerle optimal konu sayÄ±sÄ±nÄ± hesaplar
    
    Args:
        num_documents: Toplam belge sayÄ±sÄ±
        avg_doc_length: Ortalama belge uzunluÄŸu (kelime sayÄ±sÄ±)
        vocabulary_size: Vocabulary boyutu
    
    Returns:
        dict: FarklÄ± yÃ¶ntemlerle hesaplanan konu sayÄ±larÄ±
    """
    
    results = {}
    
    # 1. Square Root Rule
    results['sqrt_rule'] = int(math.sqrt(num_documents))
    
    # 2. Log Rule  
    results['log_rule'] = int(math.log10(num_documents) * 10)
    
    # 3. Fixed Ratio Rules
    results['ratio_50'] = int(num_documents / 50)    # Her konuda ~50 belge
    results['ratio_100'] = int(num_documents / 100)   # Her konuda ~100 belge
    results['ratio_200'] = int(num_documents / 200)   # Her konuda ~200 belge
    results['ratio_500'] = int(num_documents / 500)   # Her konuda ~500 belge
    
    # 4. Logarithmic Scale (Natural Log)
    results['ln_rule'] = int(math.log(num_documents))
    
    # 5. Power Rule (n^0.3)
    results['power_rule'] = int(num_documents ** 0.3)
    
    # 6. Academic Literature Based (Griffiths & Steyvers 2004)
    # T = K * log(M) where K is a constant, M is number of documents
    results['griffiths_k1'] = int(1 * math.log(num_documents))
    results['griffiths_k5'] = int(5 * math.log(num_documents))
    results['griffiths_k10'] = int(10 * math.log(num_documents))
    
    # 7. Blei et al. 2003 approach (smaller topic numbers for better interpretation)
    results['blei_conservative'] = min(100, int(math.sqrt(num_documents) * 0.5))
    
    # 8. Large corpus specific (for 100k+ documents)
    if num_documents >= 100000:
        results['large_corpus_low'] = int(num_documents / 1000)   # Her konuda ~1000 belge
        results['large_corpus_mid'] = int(num_documents / 750)    # Her konuda ~750 belge
        results['large_corpus_high'] = int(num_documents / 500)   # Her konuda ~500 belge
    
    # 9. Balanced approach (trade-off between granularity and interpretability)
    balanced = int(math.sqrt(num_documents) * 1.5)
    results['balanced'] = min(500, max(50, balanced))  # 50-500 arasÄ± sÄ±nÄ±rla
    
    return results

def analyze_topic_distribution(num_documents, topic_counts):
    """
    Her konu sayÄ±sÄ± iÃ§in istatistikleri hesaplar
    """
    analysis = {}
    
    for method, topics in topic_counts.items():
        docs_per_topic = num_documents / topics
        analysis[method] = {
            'topics': topics,
            'docs_per_topic': round(docs_per_topic, 1),
            'topics_per_1k_docs': round(topics / (num_documents / 1000), 2),
            'interpretability': 'High' if topics <= 100 else 'Medium' if topics <= 300 else 'Low',
            'granularity': 'High' if docs_per_topic <= 200 else 'Medium' if docs_per_topic <= 500 else 'Low'
        }
    
    return analysis

def recommend_optimal_range(results, analysis):
    """
    Optimal aralÄ±k Ã¶nerisi
    """
    # FarklÄ± kriterlere gÃ¶re filtreleme
    good_candidates = []
    
    for method, stats in analysis.items():
        topics = stats['topics']
        docs_per_topic = stats['docs_per_topic']
        
        # Kriterler:
        # - 50-400 konu arasÄ± (interpretability iÃ§in)
        # - Konu baÅŸÄ±na 200-1000 belge arasÄ± (statistical power iÃ§in)
        # - Ã‡ok kÃ¼Ã§Ã¼k veya Ã§ok bÃ¼yÃ¼k deÄŸilse
        
        if (50 <= topics <= 400 and 
            200 <= docs_per_topic <= 1000):
            good_candidates.append((method, topics, docs_per_topic))
    
    # En iyi adaylarÄ± sÄ±rala (konu baÅŸÄ±na belge sayÄ±sÄ±na gÃ¶re)
    good_candidates.sort(key=lambda x: abs(x[2] - 400))  # 400 belge/konu ideal
    
    return good_candidates

def main():
    """Ana hesaplama ve analiz"""
    
    # MANTIS dataset bilgileri
    num_documents = 103576
    print(f"MANTIS Dataset: {num_documents:,} makale")
    print("=" * 60)
    
    # Optimal konu sayÄ±larÄ±nÄ± hesapla
    topic_results = calculate_optimal_topics(num_documents)
    
    # Analiz et
    analysis = analyze_topic_distribution(num_documents, topic_results)
    
    # SonuÃ§larÄ± yazdÄ±r
    print("\nFarklÄ± YÃ¶ntemlerle Hesaplanan Konu SayÄ±larÄ±:")
    print("-" * 60)
    print(f"{'YÃ¶ntem':<20} {'Konu':<8} {'Belge/Konu':<12} {'Yorumlanabilirlik':<15} {'AyrÄ±ntÄ±'}")
    print("-" * 60)
    
    for method, stats in sorted(analysis.items(), key=lambda x: x[1]['topics']):
        print(f"{method:<20} {stats['topics']:<8} {stats['docs_per_topic']:<12} "
              f"{stats['interpretability']:<15} {stats['granularity']}")
    
    # Optimal aralÄ±k Ã¶nerisi
    recommendations = recommend_optimal_range(topic_results, analysis)
    
    print("\n" + "=" * 60)
    print("Ã–NERÄ°LEN OPTIMAL KONU SAYILARI:")
    print("=" * 60)
    
    if recommendations:
        print("\nEn iyi adaylar (konu baÅŸÄ±na 200-1000 belge arasÄ±):")
        for i, (method, topics, docs_per_topic) in enumerate(recommendations[:5], 1):
            print(f"{i}. {method}: {topics} konu ({docs_per_topic:.1f} belge/konu)")
        
        # En Ã¶nerilen
        best_method, best_topics, best_docs_per_topic = recommendations[0]
        print(f"\nğŸ¯ EN Ã–NERÄ°LEN: {best_topics} konu")
        print(f"   YÃ¶ntem: {best_method}")
        print(f"   Konu baÅŸÄ±na: {best_docs_per_topic:.1f} belge")
        
    else:
        # Fallback Ã¶neriler
        print("\nAlternatif Ã¶neriler:")
        sorted_methods = sorted(analysis.items(), key=lambda x: abs(x[1]['docs_per_topic'] - 400))
        for method, stats in sorted_methods[:3]:
            print(f"- {method}: {stats['topics']} konu ({stats['docs_per_topic']:.1f} belge/konu)")
    
    # Akademik literatÃ¼r perspektifi
    print(f"\nğŸ“š AKADEMIK LÄ°TERATÃœR Ã–NERÄ°LERÄ°:")
    print(f"- Griffiths & Steyvers (2004): {topic_results['griffiths_k10']} konu")
    print(f"- Blei et al. konservatif: {topic_results['blei_conservative']} konu")
    print(f"- BÃ¼yÃ¼k korpus ortalamasÄ±: {topic_results['large_corpus_mid']} konu")
    
    # Mevcut durumla karÅŸÄ±laÅŸtÄ±rma
    current_15 = num_documents / 15  # Mevcut 15 konu
    current_120 = num_documents / 120  # Yeni 120 konu
    
    print(f"\nğŸ“Š MEVCUT DURUMLA KARÅILAÅTIRMA:")
    print(f"- Mevcut (15 konu): {current_15:.0f} belge/konu (Ã‡OK FAZLA - Poor discrimination)")
    print(f"- Åu anki (120 konu): {current_120:.0f} belge/konu (Ä°yi aralÄ±kta)")
    
    # Final Ã¶neri
    print(f"\nğŸ”¥ FÄ°NAL Ã–NERÄ°:")
    if recommendations:
        final_recommendation = recommendations[0][1]
    else:
        # 103k belge iÃ§in optimal: ~250-300 konu arasÄ±
        final_recommendation = topic_results['ratio_100']  # ~1036 topics
        if final_recommendation > 400:
            final_recommendation = min(300, topic_results['balanced'])
    
    print(f"   {num_documents:,} makale iÃ§in optimal konu sayÄ±sÄ±: {final_recommendation}")
    print(f"   Bu sayede konu baÅŸÄ±na yaklaÅŸÄ±k {num_documents/final_recommendation:.0f} belge olur.")
    print(f"   Hem iyi ayrÄ±ÅŸtÄ±rma hem de yorumlanabilirlik saÄŸlar.")

if __name__ == "__main__":
    main()